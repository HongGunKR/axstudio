{
  "data": {
    "edges": [
      {
        "animated": false,
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-NPnXv",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "chat_input",
            "id": "CoEModelPicker-tbd4i",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ChatInput-NPnXv{œdataTypeœ:œChatInputœ,œidœ:œChatInput-NPnXvœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-CoEModelPicker-tbd4i{œfieldNameœ:œchat_inputœ,œidœ:œCoEModelPicker-tbd4iœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ChatInput-NPnXv",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-NPnXvœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CoEModelPicker-tbd4i",
        "targetHandle": "{œfieldNameœ:œchat_inputœ,œidœ:œCoEModelPicker-tbd4iœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-o7Itl",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "prompt",
            "id": "CoEModelPicker-tbd4i",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Prompt-o7Itl{œdataTypeœ:œPromptœ,œidœ:œPrompt-o7Itlœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-CoEModelPicker-tbd4i{œfieldNameœ:œpromptœ,œidœ:œCoEModelPicker-tbd4iœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-o7Itl",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-o7Itlœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CoEModelPicker-tbd4i",
        "targetHandle": "{œfieldNameœ:œpromptœ,œidœ:œCoEModelPicker-tbd4iœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "data": {
          "sourceHandle": {
            "dataType": "CoEModelPicker",
            "id": "CoEModelPicker-tbd4i",
            "name": "chat_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-a3e2w",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__CoEModelPicker-tbd4i{œdataTypeœ:œCoEModelPickerœ,œidœ:œCoEModelPicker-tbd4iœ,œnameœ:œchat_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-a3e2w{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-a3e2wœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "CoEModelPicker-tbd4i",
        "sourceHandle": "{œdataTypeœ:œCoEModelPickerœ,œidœ:œCoEModelPicker-tbd4iœ,œnameœ:œchat_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-a3e2w",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-a3e2wœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œstrœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "description": "Get chat inputs from the Playground.",
          "display_name": "Chat Input",
          "id": "ChatInput-NPnXv",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "store_message",
              "sender",
              "sender_name",
              "session_id",
              "files"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.4.2",
            "metadata": {
              "code_hash": "192913db3453",
              "module": "langflow.components.input_output.chat.ChatInput"
            },
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chat Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs.inputs import BoolInput\nfrom langflow.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-input\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n            temp_file=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Chat Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        background_color = self.background_color\n        text_color = self.text_color\n        icon = self.chat_icon\n\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\n                \"background_color\": background_color,\n                \"text_color\": text_color,\n                \"icon\": icon,\n            },\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "files": {
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "name": "files",
                "placeholder": "",
                "required": false,
                "show": true,
                "temp_file": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "advanced": false,
                "display_name": "Input Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Hello"
              },
              "sender": {
                "advanced": true,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            }
          },
          "selected_output": "message",
          "type": "ChatInput"
        },
        "dragging": false,
        "height": 234,
        "id": "ChatInput-NPnXv",
        "measured": {
          "height": 234,
          "width": 320
        },
        "position": {
          "x": 689.5720422421635,
          "y": 765.155834131403
        },
        "positionAbsolute": {
          "x": 689.5720422421635,
          "y": 765.155834131403
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt",
          "id": "Prompt-o7Itl",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": []
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "metadata": {
              "code_hash": "3bf0b511e227",
              "module": "langflow.components.prompts.prompt.PromptComponent"
            },
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "load_from_db": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "[역할]\n당신은 생성형 AI(GenAI) 전문가입니다.\n사용자가 새로운 것을 쉽게 만들수 있도록 열정적으로 돕고 싶어하는 태도로 답하세요."
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "selected_output": "prompt",
          "type": "Prompt"
        },
        "dragging": false,
        "height": 260,
        "id": "Prompt-o7Itl",
        "measured": {
          "height": 260,
          "width": 320
        },
        "position": {
          "x": 688.9222183027662,
          "y": 1044.5004597498394
        },
        "positionAbsolute": {
          "x": 690.2015147036818,
          "y": 1018.5443911764344
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "undefined-8vLbv",
          "node": {
            "description": "# 📖 README\n이 템플릿은 추가 지시문이 포함된 표준 채팅 플로우를 보여줍니다.\n프롬프트(Prompt)는 사용자가 직접 입력하는 채팅 이외에, **대규모 언어 모델(LLM)**에 대한 지시사항과 입력값을 제공합니다.\n이 예시에서는 프롬프트가 LLM의 역할과 페르소나(persona)를 설명합니다.\n\n## Quick Start\n1. Language Model 컴포넌트에 OpenAI API 키를 추가하거나, 다른 공급자와 모델을 선택하세요.\n2. Playground를 열어 채팅을 시작하고 플로우를 실행하세요.\n\n## Next steps\n프롬프트 템플릿, 모델, 또는 모델 설정(예: Temperature)을 변경해 보세요. 입력값이 달라졌을 때 응답이 어떻게 바뀌는지 확인해 보세요.\n\n💡 일부 컴포넌트 설정은 기본적으로 숨겨져 있습니다. 모든 설정을 보려면 각 컴포넌트의 헤더 메뉴에서 Controls를 클릭하세요.\n\n💡 템플릿에 {variable}처럼 중괄호를 사용하여 변수를 만들 수 있습니다. 이 변수는 다른 컴포넌트, Langflow 전역 변수, 또는 실행 시점(Runtime)에서 채워질 수 있습니다.",
            "display_name": "Read Me",
            "documentation": "",
            "template": {
              "backgroundColor": "amber"
            }
          }
        },
        "dragging": false,
        "height": 624,
        "id": "undefined-8vLbv",
        "measured": {
          "height": 624,
          "width": 429
        },
        "position": {
          "x": 237.97591781380908,
          "y": 694.6960630534636
        },
        "positionAbsolute": {
          "x": 66.38770028934243,
          "y": 749.744424427066
        },
        "resizing": false,
        "selected": false,
        "style": {
          "height": 250,
          "width": 324
        },
        "type": "noteNode",
        "width": 429
      },
      {
        "data": {
          "id": "ChatOutput-a3e2w",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.4.2",
            "metadata": {
              "code_hash": "6f74e04e39d5",
              "module": "langflow.components.input_output.chat_output.ChatOutput"
            },
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean the data",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.template.field.base import Output\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([safe_convert(item, clean_data=self.clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "type": "ChatOutput"
        },
        "dragging": false,
        "height": 234,
        "id": "ChatOutput-a3e2w",
        "measured": {
          "height": 234,
          "width": 320
        },
        "position": {
          "x": 1460.070372772908,
          "y": 872.7273956769025
        },
        "positionAbsolute": {
          "x": 1444.936881624563,
          "y": 872.7273956769025
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "CoEModelPicker-tbd4i",
          "node": {
            "base_classes": [
              "Any",
              "Message",
              "Text"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Pick a model by name then call /v1/chat/completions.",
            "display_name": "CoE Agents",
            "documentation": "",
            "edited": false,
            "field_order": [
              "chat_input",
              "prompt",
              "model_name",
              "backend_url",
              "force_https",
              "refresh_now"
            ],
            "frozen": false,
            "icon": "server",
            "last_updated": "2025-09-15T05:01:31.330Z",
            "legacy": false,
            "metadata": {
              "code_hash": "33fd6265e66f",
              "module": "langflow.components.agents.coe_model_picker.CoEModelPicker"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chat Output",
                "group_outputs": false,
                "method": "run_message",
                "name": "chat_output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message",
                  "Text",
                  "Any"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Text Output",
                "group_outputs": false,
                "method": "run_text",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "selected": "Text",
                "tool_mode": true,
                "types": [
                  "Text",
                  "Any"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model ID",
                "group_outputs": false,
                "method": "get_model_id",
                "name": "model_id",
                "options": null,
                "required_inputs": null,
                "selected": "Text",
                "tool_mode": true,
                "types": [
                  "Text"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "template": {
              "_type": "Component",
              "backend_url": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "CoE Backend URL",
                "dynamic": false,
                "info": "mac/Windows: http://greatcoe.cafe24.com",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "backend_url",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "http://greatcoe.cafe24.com:8080"
              },
              "chat_input": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Chat Input",
                "dynamic": false,
                "info": "User message to send to the selected model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_input",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "# coe_model_picker.py\n# -*- coding: utf-8 -*-\nfrom __future__ import annotations\n\nimport json\nimport os\nimport socket\nfrom typing import Any, Dict, List, Tuple, Optional\n\n# stdlib HTTP\nimport urllib.request as urlreq\nfrom urllib.error import URLError\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import BoolInput, MessageInput, MultilineInput\nfrom langflow.io import DropdownInput, Output\n\n# Langflow Message (버전 호환)\ntry:\n    from langflow.schema.message import Message  # Langflow >= 1.0\nexcept Exception:  # pragma: no cover\n    try:\n        from langflow.schema import Message  # 일부 구버전\n    except Exception:  # pragma: no cover\n        Message = None  # type: ignore\n\nALLOWED_OWNERS = {\"openai\", \"sktax\"}\nDEFAULT_BACKEND = os.getenv(\"COE_BACKEND_URL\", \"http://host.docker.internal:8000\").strip().rstrip(\"/\")\n\n\ndef _http_get_json(url: str, timeout: float = 8.0) -> Dict[str, Any]:\n    req = urlreq.Request(url, headers={\"User-Agent\": \"langflow\"})\n    with urlreq.urlopen(req, timeout=timeout) as r:\n        return json.loads(r.read().decode(\"utf-8\"))\n\n\ndef _http_post_json(url: str, payload: Dict[str, Any], timeout: float = 30.0) -> Dict[str, Any]:\n    data = json.dumps(payload).encode(\"utf-8\")\n    req = urlreq.Request(url, data=data, headers={\"Content-Type\": \"application/json\", \"User-Agent\": \"langflow\"})\n    with urlreq.urlopen(req, timeout=timeout) as r:\n        return json.loads(r.read().decode(\"utf-8\"))\n\n\nclass CoEModelPicker(Component):\n    \"\"\"\n    /v1/models에서 모델 목록을 name으로 표시(owned_by ∈ {openai, sktax} 필터),\n    선택한 모델로 /v1/chat/completions를 호출합니다.\n\n    출력:\n      - chat_output (Message 타입): Chat Output 싱크에 연결\n      - text_output (Text 타입): Text Output 싱크에 연결\n      - model_id (Text): 선택 모델의 id\n    \"\"\"\n\n    display_name = \"CoE Agents\"\n    description = \"Pick a model by name then call /v1/chat/completions.\"\n    icon = \"server\"\n    category = \"agents\"\n    priority = 0\n\n    # name -> id 매핑(런타임에 채움)\n    _name_to_id: Dict[str, str] = {}\n    # 최근 호출 결과 캐시\n    _last_text: Optional[str] = None\n\n    # ★ 첫 렌더링(마운트) 시 자동 로드 제어 플래그\n    _did_initial_fetch: bool = False\n\n    # ─────────────────────────────────────────────────────────────────────────\n    # Inputs\n    inputs = [\n        MessageInput(\n            name=\"chat_input\",\n            display_name=\"Chat Input\",\n            info=\"User message to send to the selected model.\",\n        ),\n        MultilineInput(\n            name=\"prompt\",\n            display_name=\"Prompt (System)\",\n            info=\"Optional system prompt (system role).\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model\",\n            # ★ 초기엔 빈 옵션으로 두고(placeholder 제거) 자동 로드 유도\n            options=[],\n            value=\"\",\n            info=\"Models filtered by owned_by (openai, sktax).\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"backend_url\",\n            display_name=\"CoE Backend URL\",\n            value=DEFAULT_BACKEND,\n            info=\"mac/Windows: http://greatcoe.cafe24.com\",\n            advanced=True,\n            real_time_refresh=True,\n        ),\n        BoolInput(\n            name=\"force_https\",\n            display_name=\"Force HTTPS\",\n            value=False,\n            advanced=True,\n            real_time_refresh=True,\n        ),\n        BoolInput(\n            name=\"refresh_now\",\n            display_name=\"Refresh models now\",\n            value=False,\n            info=\"Toggle to refresh the model list.\",\n            advanced=True,\n            real_time_refresh=True,\n        ),\n    ]\n\n    # ─────────────────────────────────────────────────────────────────────────\n    # Outputs\n    outputs = [\n        Output(\n            display_name=\"Chat Output\",\n            name=\"chat_output\",\n            method=\"run_message\",\n            types=[\"Message\", \"Text\", \"Any\"],\n            selected=\"Message\",\n        ),\n        Output(\n            display_name=\"Text Output\",\n            name=\"text_output\",\n            method=\"run_text\",\n            types=[\"Text\", \"Any\"],\n            selected=\"Text\",\n        ),\n        Output(\n            display_name=\"Model ID\",\n            name=\"model_id\",\n            method=\"get_model_id\",\n            types=[\"Text\"],\n            selected=\"Text\",\n        ),\n    ]\n\n    # ─────────────────────────────────────────────────────────────────────────\n    # 내부 유틸\n    @staticmethod\n    def _normalize(base: str, force_https: bool) -> str:\n        base = (base or DEFAULT_BACKEND).strip()\n        if force_https and base.startswith(\"http://\"):\n            base = \"https://\" + base[len(\"http://\") :]\n        return base.rstrip(\"/\")\n\n    @staticmethod\n    def _linux_fallback(base: str) -> str:\n        return base.replace(\"host.docker.internal\", \"172.17.0.1\") if \"host.docker.internal\" in base else base\n\n    @staticmethod\n    def _fallback_pairs() -> List[Tuple[str, str]]:\n        return [\n            (\"GPT-4o Mini\", \"gpt-4o-mini\"),\n            (\"GPT-4o\", \"gpt-4o\"),\n            (\"text-embedding-3-small\", \"text-embedding-3-small\"),\n            (\"AX4 Model\", \"ax4\"),\n        ]\n\n    def _fetch_models(self, base_url: str) -> List[Tuple[str, str]]:\n        \"\"\"서버에서 모델 목록을 받아 (name, id)로 반환(필터 적용)\"\"\"\n        url = base_url + \"/v1/models\"\n\n        def _try(u: str) -> Dict[str, Any]:\n            return _http_get_json(u, timeout=8.0)\n\n        try:\n            payload = _try(url)\n        except (URLError, OSError, socket.gaierror):\n            fb = self._linux_fallback(base_url) + \"/v1/models\"\n            self.log(f\"[CoEModelPicker] retry: {fb}\")\n            payload = _try(fb)\n\n        data = (payload.get(\"result\") or {}).get(\"data\") or payload.get(\"data\") or []\n        pairs: List[Tuple[str, str]] = []\n        for item in data:\n            if not isinstance(item, dict):\n                continue\n            owner = str(item.get(\"owned_by\") or \"\").strip().lower()\n            if owner not in ALLOWED_OWNERS:\n                continue\n            mid = str(item.get(\"id\") or \"\").strip()\n            name = str(item.get(\"name\") or mid).strip()\n            if mid and name:\n                pairs.append((name, mid))\n        pairs.sort(key=lambda x: x[0].lower())\n        return pairs\n\n    # ─────────────────────────────────────────────────────────────────────────\n    # 동적 UI 반영\n    def update_build_config(self, build_config, field_value: Any, field_name: str | None = None):\n        current_base = build_config.get(\"backend_url\", {}).get(\"value\", DEFAULT_BACKEND)\n        current_force_https = bool(build_config.get(\"force_https\", {}).get(\"value\", False))\n        if field_name == \"backend_url\":\n            current_base = field_value\n        elif field_name == \"force_https\":\n            current_force_https = bool(field_value)\n\n        base = self._normalize(current_base, current_force_https)\n\n        current_options = build_config.get(\"model_name\", {}).get(\"options\") or []\n        current_value = (build_config.get(\"model_name\", {}) or {}).get(\"value\") or \"\"\n\n        # ★ 최초 마운트 또는 옵션이 비어있을 때/수동 토글 시 새로고침\n        should_refresh = (\n            not self._did_initial_fetch\n            or field_name in {\"backend_url\", \"force_https\", \"refresh_now\"}\n            or not current_options\n            or current_value == \"(click Refresh models now)\"\n        )\n\n        if should_refresh:\n            try:\n                pairs = self._fetch_models(base)\n                if pairs:\n                    self._name_to_id = {name: mid for name, mid in pairs}\n                    names = list(self._name_to_id.keys())\n                    build_config[\"model_name\"][\"options\"] = names\n                    if not current_value or current_value not in names:\n                        build_config[\"model_name\"][\"value\"] = names[0]\n                    self._did_initial_fetch = True  # ★ 한 번 성공하면 플래그 켜기\n                    self.log(f\"[CoEModelPicker] models loaded: {len(names)} from {base}\")\n                else:\n                    # 서버 응답이 비었을 때 폴백\n                    pairs = self._fallback_pairs()\n                    self._name_to_id = {n: i for n, i in pairs}\n                    names = [n for n, _ in pairs]\n                    build_config[\"model_name\"][\"options\"] = names\n                    if not current_value or current_value not in names:\n                        build_config[\"model_name\"][\"value\"] = names[0]\n                    self._did_initial_fetch = True\n                    self.log(\"[CoEModelPicker] server returned empty; using fallback\")\n            except Exception as e:\n                # 실패 시 폴백 후에도 초기화 완료 처리 (UI가 비지 않도록)\n                pairs = self._fallback_pairs()\n                self._name_to_id = {n: i for n, i in pairs}\n                names = [n for n, _ in pairs]\n                build_config[\"model_name\"][\"options\"] = names\n                if not current_value or current_value not in names:\n                    build_config[\"model_name\"][\"value\"] = names[0]\n                self._did_initial_fetch = True\n                self.log(f\"[CoEModelPicker] fetch failed: {e}; using fallback list\")\n\n            # ★ 수동 토글이 켜져 있으면 끄면서(체크 해제) UI 깜빡임 방지\n            if \"refresh_now\" in build_config:\n                build_config[\"refresh_now\"][\"value\"] = False\n\n        return build_config\n\n    # ─────────────────────────────────────────────────────────────────────────\n    # 입력 수집\n    def _collect_inputs(self) -> Tuple[str, str, str, str, bool]:\n        # chat_input → Message 객체(.text) 또는 dict(data.text) 또는 str\n        chat_text = \"\"\n        msg = getattr(self, \"chat_input\", None)\n        try:\n            if msg is not None:\n                # Message 타입\n                chat_text = getattr(msg, \"text\", \"\") or \"\"\n                if not chat_text and hasattr(msg, \"data\") and isinstance(msg.data, dict):\n                    chat_text = msg.data.get(\"text\") or \"\"\n                if not chat_text and isinstance(msg, str):\n                    chat_text = msg\n        except Exception:\n            pass\n\n        prompt = (getattr(self, \"prompt\", \"\") or \"\").strip()\n        model_name = (getattr(self, \"model_name\", \"\") or \"\").strip()\n        backend_url = (getattr(self, \"backend_url\", \"\") or DEFAULT_BACKEND).strip()\n        force_https = bool(getattr(self, \"force_https\", False))\n        return chat_text, prompt, model_name, backend_url, force_https\n\n    # ─────────────────────────────────────────────────────────────────────────\n    # 공통 호출(한 번만 호출해서 캐시)\n    def _call_chat(\n        self,\n        chat_input: str,\n        prompt: str,\n        model_name: str,\n        backend_url: str,\n        force_https: bool,\n    ) -> str:\n        if self._last_text is not None:\n            return self._last_text\n\n        model_id = self._name_to_id.get(model_name or \"\", \"\")\n        if not model_id:\n            fpairs = self._fallback_pairs()\n            if fpairs:\n                model_id = fpairs[0][1]\n\n        base = self._normalize(backend_url or DEFAULT_BACKEND, bool(force_https))\n        url = base + \"/v1/chat/completions\"\n        fb = self._linux_fallback(base)\n\n        messages: List[Dict[str, Any]] = []\n        if prompt:\n            messages.append({\"role\": \"system\", \"content\": str(prompt)})\n        messages.append({\"role\": \"user\", \"content\": str(chat_input or \"\")})\n\n        payload = {\"model\": model_id or (model_name or \"\"), \"messages\": messages}\n\n        def _try(u: str) -> Dict[str, Any]:\n            return _http_post_json(u, payload, timeout=30.0)\n\n        try:\n            resp = _try(url)\n        except (URLError, OSError, socket.gaierror):\n            if base != fb:\n                resp = _try(fb + \"/v1/chat/completions\")\n            else:\n                raise\n\n        try:\n            choice0 = (resp.get(\"choices\") or [])[0]\n            msg = (choice0.get(\"message\") or {})\n            content = msg.get(\"content\") or \"\"\n            self._last_text = str(content)\n            return self._last_text\n        except Exception:\n            self._last_text = json.dumps(resp, ensure_ascii=False)[:2000]\n            return self._last_text\n\n    # ─────────────────────────────────────────────────────────────────────────\n    # Outputs 구현\n    def run_message(self, **kwargs: Any):\n        chat_text, prompt, model_name, backend_url, force_https = self._collect_inputs()\n        text = self._call_chat(chat_text, prompt, model_name, backend_url, force_https)\n        if Message is not None:\n            try:\n                return Message(text=text)\n            except Exception:\n                pass\n        # 폴백: Langflow가 dict도 표시 가능\n        return {\"text\": text, \"sender\": \"AI\"}\n\n    def run_text(self, **kwargs: Any) -> str:\n        chat_text, prompt, model_name, backend_url, force_https = self._collect_inputs()\n        return self._call_chat(chat_text, prompt, model_name, backend_url, force_https)\n\n    def get_model_id(self) -> str:\n        name = (getattr(self, \"model_name\", \"\") or \"\").strip()\n        return self._name_to_id.get(name, \"\")\n"
              },
              "force_https": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Force HTTPS",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "force_https",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model",
                "dynamic": false,
                "info": "Models filtered by owned_by (openai, sktax).",
                "name": "model_name",
                "options": [
                  "AX4 Model",
                  "GPT-4o",
                  "GPT-4o Mini",
                  "OpenAI Embedding v3 Small"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AX4 Model"
              },
              "prompt": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Prompt (System)",
                "dynamic": false,
                "info": "Optional system prompt (system role).",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "prompt",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "refresh_now": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Refresh models now",
                "dynamic": false,
                "info": "Toggle to refresh the model list.",
                "list": false,
                "list_add_label": "Add More",
                "name": "refresh_now",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              }
            },
            "tool_mode": false
          },
          "selected_output": "chat_output",
          "showNode": true,
          "type": "CoEModelPicker"
        },
        "dragging": false,
        "id": "CoEModelPicker-tbd4i",
        "measured": {
          "height": 384,
          "width": 320
        },
        "position": {
          "x": 1084.724452379434,
          "y": 804.9212996358931
        },
        "selected": false,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": -144.53404364583957,
      "y": -507.2065447874029,
      "zoom": 0.880500792046506
    }
  },
  "description": "LLM모델을 활용한 Basic Prompring.",
  "endpoint_name": null,
  "id": "9b6b68af-6b6c-4e29-a0b7-edeea7b9339e",
  "is_component": false,
  "last_tested_version": "1.5.0",
  "name": "Basic Prompting",
  "tags": [
    "chatbots"
  ]
}